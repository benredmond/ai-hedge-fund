---
date: 2025-11-02T01:59:16Z
researcher: Claude
git_commit: 0c7633584f35350c05b170ac854a84ea5699cee8
branch: main
repository: ai-hedge-fund
topic: "Fix Candidate Generation Producing Basic Strategies"
tags: [research, agent, prompts, pydantic, structured-output]
status: complete
agents_deployed: 3
files_analyzed: 8
confidence_score: 9/10
---

# Research: Fix Candidate Generation Producing Basic Strategies That Fail Edge Scoring

**Date**: 2025-11-02T01:59:16Z
**Repository**: ai-hedge-fund
**Branch**: main @ 0c7633584f35350c05b170ac854a84ea5699cee8
**Research Coverage**: 3 parallel agents, 8 files analyzed

## Executive Summary

The candidate generation stage produces minimal strategies (just assets/weights) that fail edge scoring validation despite 782 lines of detailed prompts demanding comprehensive thesis, edge articulation, and risk frameworks.

**Root Cause**: **Type-driven information loss**. The `Strategy` Pydantic model only captures execution parameters (assets, weights, rebalance_frequency) but lacks fields for strategic reasoning (thesis, edge, failure_modes). When `output_type=List[Strategy]` forces schema compliance, all strategic reasoning generated by the LLM is **discarded** because there's nowhere to store it.

**Impact**:
- Generated strategy "Growth Momentum Leaders" scored 2/1/2 (needs 3/3/3)
- Edge scorer receives only ticker lists, cannot evaluate thesis quality or edge economics
- Workflow structurally broken: prompts request information the schema cannot capture

**Recommended Solution**: Solution A (Schema Extension + Multi-Turn Workflow) - Add reasoning fields to Strategy model, restructure prompts into sequential conversation turns, and leverage research-proven field ordering techniques.

---

## Research Question

**Original Query**: "Help me come up with a plan to fix the 5 generated plans not being comprehensive. They are extremely basic. It feels like the AI is not adhering at all to the prompt that I am giving for the candidate generation."

**Test Failure Evidence**:
```
Strategy(name='Growth Momentum Leaders', assets=['XLK', 'XLY', 'XLV'],
         weights={'XLK': 0.45, 'XLY': 0.35, 'XLV': 0.2},
         rebalance_frequency='monthly', logic_tree={})

Edge Scorecard Results:
- Thesis Quality: 2/5 (needs ≥3) - "No thesis articulated"
- Edge Economics: 1/5 (needs ≥3) - "No edge claimed or explained"
- Risk Framework: 2/5 (needs ≥3) - "No risk framework presented"
```

---

## Root Cause Analysis

### Primary Issue: Type-Driven Information Loss

**Problem**: The `Strategy` Pydantic model acts as a lossy filter that discards strategic reasoning.

**Evidence**:

1. **Prompts Request Comprehensive Reasoning** (`src/agent/prompts/candidate_generation.md:111-131`):
   ```markdown
   For each candidate, complete:

   Edge: [Specific inefficiency - e.g., "Momentum persistence"]
   Why it exists: [Mechanism - e.g., "Institutional capital flows lag"]
   Why now: [Regime fit - cite Phase 1 data]
   Archetype: [momentum|mean reversion|carry|...]
   Failure mode: [Specific condition - e.g., "VIX > 25"]
   ```

2. **Strategy Model Missing Critical Fields** (`src/agent/models.py:29-113`):
   ```python
   class Strategy(BaseModel):
       name: str
       assets: List[str]
       weights: Dict[str, float]
       rebalance_frequency: RebalanceFrequency
       logic_tree: Dict[str, Any] = Field(default_factory=dict)
       # ❌ Missing: thesis, edge, edge_type, why_now, archetype, failure_modes
   ```

3. **Edge Scorer Receives Incomplete Data** (`src/agent/stages/edge_scorer.py:66-72`):
   ```python
   strategy_json = {
       "name": strategy.name,
       "assets": strategy.assets,
       "weights": strategy.weights,
       "rebalance_frequency": strategy.rebalance_frequency.value,
       "logic_tree": strategy.logic_tree if strategy.logic_tree else {}
       # ❌ No thesis, edge, or failure_modes to evaluate
   }
   ```

**Information Flow Gap**:
```
Prompts Request          Strategy Model Captures       Edge Scorer Needs
─────────────────        ───────────────────────       ─────────────────
✓ Edge explanation    →  ❌ No field                →  ✓ Edge Economics dimension
✓ Why it exists       →  ❌ No field                →  ✓ Thesis Quality dimension
✓ Failure modes       →  ❌ No field                →  ✓ Risk Framework dimension
✓ Why now (regime)    →  ❌ No field                →  ✓ Regime Awareness dimension
✓ Archetype           →  ❌ No field                →  ✓ Strategic Coherence dimension
```

**Execution Trace**:
```
candidate_generator.py:107  → output_type=List[Strategy]  [Forces schema compliance]
                     :184  → result = agent.run(...)      [LLM generates reasoning]
                     :189  → return result.output          [Reasoning discarded, only schema fields kept]
                            ↓
edge_scorer.py:66-72       → Serializes only: name, assets, weights, rebalance_frequency
                     :78   → Sends to edge scorer           [Missing all thesis/edge/risk data]
                            ↓
Edge Scoring FAILS         → Cannot evaluate thesis quality from ticker list alone
```

---

### Contributing Factors

#### 1. Kimi K2 Model Limitations (Researched)

**Finding**: Kimi K2 has documented performance issues with monolithic prompts.

**Evidence from Web Research**:
- "Kimi K2 shows decreased performance with one-shot prompting rather than agentic workflows" (DataCamp)
- "The depth-of-thought problem is hard to change - like an intern who can't produce a VP-level report despite prompting" (grapeot.me)
- Recommended: temperature = 0.6, multi-turn workflows with tool chaining

**Your Current Setup**:
- 782-line single-shot prompt (system: 421 lines + recipe: 361 lines)
- Single `agent.run()` call expecting comprehensive output
- Fighting against Kimi K2's architecture

**Impact**: Even if schema is fixed, Kimi K2 may lack strategic depth for institutional-grade thesis generation.

#### 2. Field Ordering Reduces Reasoning Quality (Research-Proven)

**Finding**: Placing reasoning fields AFTER answer fields reduces LLM performance by 60%.

**Evidence from Research**:
- "Ordering JSON fields so that the reasoning field comes before the answer field improves results by a huge margin" (Dylan Castillo)
- "Field order critically affects reasoning - LLMs generate sequentially, earlier parts influence later parts" (dsdev.in)

**Your Current Model** (`models.py:29-45`):
```python
class Strategy(BaseModel):
    name: str              # ← Execution fields FIRST
    assets: List[str]      # ← LLM fills these, considers task "done"
    weights: Dict[str, float]
    rebalance_frequency: RebalanceFrequency
    logic_tree: Dict[str, Any] = Field(default_factory=dict)
    # Reasoning would come last (if it existed)
```

**Impact**: LLM generates `name`, `assets`, `weights` first, then considers the task complete because it satisfied the required fields. Research shows models perform 60% better when reasoning fields come FIRST.

#### 3. Long Prompt Attention Degradation

**Finding**: LLMs experience attention degradation starting at ~3,000 tokens, well below technical limits.

**Evidence from Research**:
- "LLMs experience degradation in reasoning performance around 3,000 tokens" (Research paper: "Same Task, More Tokens")
- "Lost in the middle" effect - information buried mid-prompt is systematically ignored
- "16K-token well-structured prompt with RAG outperforms 128K-token monolithic prompt"

**Your Current Prompts**:
- System prompt: 421 lines
- Recipe prompt: 361 lines
- Combined: 782 lines (~6,500 tokens estimated)
- Diversity requirements, mental models checklist buried in middle

**Impact**: Critical instructions about edge articulation and diversity exploration are being ignored due to positional bias.

#### 4. Structured Output vs Reasoning Trade-Off

**Finding**: Strict structured output constraints reduce LLM reasoning capabilities.

**Evidence from Research**:
- "Format constraints negatively impact quality when combined with reasoning tasks" (Instill AI)
- "Stricter format restrictions lead to more performance drops in reasoning" (Research)
- "Adding a reasoning field increased model accuracy by 60%" (Towards Data Science)

**Your Current Approach**:
- Forces `output_type=List[Strategy]` (strict schema)
- No reasoning fields in schema
- LLM must choose: follow prompts OR satisfy schema

**Impact**: LLM prioritizes schema compliance over prompt instructions, taking the "lazy learner" shortcut.

---

## Codebase Analysis

### Files Analyzed

1. **`src/agent/stages/candidate_generator.py`** (191 lines)
   - Line 107: `output_type=List[Strategy]` enforces schema
   - Line 184: `result = await agent.run(generate_prompt)` receives LLM output
   - Line 189: Returns stripped Strategy objects
   - **Issue**: No intermediate step to capture reasoning before structural extraction

2. **`src/agent/models.py`** (113+ lines)
   - Lines 29-45: Strategy model definition
   - **Issue**: Designed for execution, not strategic documentation
   - **Missing**: thesis, edge, edge_type, why_now, archetype, failure_modes, expected_behavior

3. **`src/agent/stages/edge_scorer.py`** (151 lines)
   - Lines 66-72: Serializes only execution fields
   - Lines 78-95: Builds scoring prompt expecting thesis/edge/risk data
   - **Issue**: Expects information that was never captured

4. **`src/agent/prompts/system/candidate_generation_system.md`** (421 lines)
   - Lines 106-113: Demands edge articulation (what, why, why now, archetype, failure modes)
   - Lines 285-300: OUTPUT CONTRACT shows Strategy schema without reasoning fields
   - **Issue**: Prompt contradicts schema - instructs "Document: edge, why it exists" but schema has no fields for this

5. **`src/agent/prompts/candidate_generation.md`** (361 lines)
   - Lines 111-131: Edge Articulation Template requiring comprehensive reasoning
   - Lines 160-239: Worked examples showing rich strategies
   - **Issue**: Examples show reasoning in markdown, but Schema cannot capture it

6. **`src/agent/prompts/edge_scoring.md`** (650 lines)
   - Lines 32-104: Thesis Quality dimension - needs causal reasoning, falsifiable conditions
   - Lines 107-192: Edge Economics dimension - needs edge source, persistence logic
   - Lines 195-274: Risk Framework dimension - needs failure modes, quantified risk budget
   - **Issue**: All 5 dimensions require information not in Strategy model

### Architecture Insights

**Current Workflow** (Broken):
```
1. Load 782-line prompts requesting comprehensive reasoning
2. Create agent with output_type=List[Strategy] (execution-only schema)
3. LLM generates reasoning internally → DISCARDED by schema filter
4. Return Strategy objects with only: name, assets, weights, rebalance_frequency
5. Edge scorer receives ticker lists → Cannot evaluate thesis/edge/risk
6. Edge scoring FAILS (scores 2/1/2, needs 3/3/3)
```

**Information Loss Point**: Line 184 of `candidate_generator.py`
```python
result = await agent.run(generate_prompt)  # ← LLM output filtered by output_type
return result.output  # ← Only schema-compliant fields survive
```

---

## Web Research Findings

### LLM Prompt Adherence Patterns

**Key Findings**:

1. **Minimum Field Compliance Problem**
   - LLMs return only required fields while ignoring optional/detailed instructions
   - Source: Stack Overflow - "Why does structured output ignore optional params in Pydantic models"
   - **Applicability**: Your `logic_tree` is optional and gets ignored

2. **Field Ordering Critical for Reasoning** (60% improvement)
   - Placing reasoning fields BEFORE answer fields improves results dramatically
   - LLMs generate sequentially; earlier parts influence later parts
   - Source: Dylan Castillo, dsdev.in
   - **Applicability**: Restructure Strategy model to have reasoning fields FIRST

3. **Two-Stage Process for Quality**
   - Decompose into: (1) Generate answer without formatting, (2) Translate to structure
   - Format constraints hurt reasoning when combined with reasoning tasks
   - Source: Instill AI
   - **Applicability**: Could use intermediate free-form reasoning step

4. **Attention Degradation at 3,000 Tokens**
   - LLMs experience reasoning performance degradation around 3,000 tokens
   - "Lost in the middle" effect - middle content gets less weight
   - Source: MLOps Community, research papers
   - **Applicability**: 782-line prompts exceed attention sweet spot

5. **Kimi K2 Specific**
   - Optimized for agentic multi-turn workflows, NOT one-shot prompts
   - "One-shot prompting shows decreased performance vs agentic framework"
   - Recommended: temperature = 0.6, step-by-step workflows
   - Source: DataCamp, Hugging Face
   - **Applicability**: Current single `agent.run()` call fights model architecture

### Best Practices Identified

1. **Break complex prompts into sequential steps** - Provide 1-2 instructions at a time
2. **Reasoning field before answer** - Order JSON fields: reasoning → outcome
3. **Few-shot examples with rich outputs** - Show complete outputs, not minimal fields
4. **Explicit completeness requirements** - "You MUST populate all fields"
5. **Use provider-native structured output** - OpenAI's `response_format` vs instruction mode
6. **Agentic multi-turn for Kimi K2** - Not monolithic prompts

---

## Solution Approaches - Tree of Thought Analysis

### Solution A: Schema Extension + Multi-Turn Workflow

**Philosophy**: Fix the structural mismatch by extending the data model to capture reasoning, then leverage research-proven techniques (field ordering, multi-turn) to ensure LLM populates it.

**Implementation Path**:

1. **Extend Strategy Model** (`src/agent/models.py`):
   ```python
   class Strategy(BaseModel):
       # ✅ REASONING FIELDS FIRST (forces LLM to think before acting)
       thesis: str = Field(..., min_length=100, description="Clear investment thesis with causal reasoning")
       edge_explanation: str = Field(..., min_length=100, description="What inefficiency is exploited and why it exists")
       edge_type: EdgeType = Field(..., description="behavioral/structural/informational/risk_premium")
       why_now: str = Field(..., min_length=50, description="Regime alignment with current market conditions")
       archetype: StrategyArchetype = Field(..., description="momentum/mean_reversion/carry/directional/volatility")
       failure_modes: List[str] = Field(..., min_length=1, description="Specific conditions that break the thesis")
       expected_behavior: str = Field(..., min_length=50, description="How strategy should perform in different regimes")

       # THEN execution fields
       name: str = Field(..., min_length=1, max_length=200)
       assets: List[str] = Field(..., min_length=1, max_length=50)
       weights: Dict[str, float]
       rebalance_frequency: RebalanceFrequency
       logic_tree: Dict[str, Any] = Field(default_factory=dict)

       @field_validator('thesis', 'edge_explanation')
       @classmethod
       def validate_substantive(cls, v: str) -> str:
           """Ensure reasoning fields are substantive, not placeholders."""
           if len(v.strip()) < 50:
               raise ValueError("Must provide substantive reasoning (min 50 chars)")
           placeholder_phrases = ["TODO", "TBD", "to be determined", "N/A", "none"]
           if any(phrase in v.lower() for phrase in placeholder_phrases):
               raise ValueError("Cannot use placeholder text in reasoning fields")
           return v
   ```

2. **Add Enum Types**:
   ```python
   class EdgeType(str, Enum):
       BEHAVIORAL = "behavioral"
       STRUCTURAL = "structural"
       INFORMATIONAL = "informational"
       RISK_PREMIUM = "risk_premium"

   class StrategyArchetype(str, Enum):
       MOMENTUM = "momentum"
       MEAN_REVERSION = "mean_reversion"
       CARRY = "carry"
       DIRECTIONAL = "directional"
       VOLATILITY = "volatility"
       MULTI_STRATEGY = "multi_strategy"
   ```

3. **Break Candidate Generation into Multi-Turn Workflow**:

   **Turn 1: Research Phase** (candidate_generator.py new method):
   ```python
   async def _research_phase(self, market_context: dict, agent) -> dict:
       """Phase 1: Tool-driven market research."""
       research_prompt = """Analyze current market regime using tools.

       Use FRED tools (fred_search, fred_get_series) to classify macro regime.
       Use market context to understand trend, volatility, leadership.

       Return: {
           "macro_regime": "expansion|slowdown|recession|recovery",
           "market_trend": "bull|bear",
           "volatility_regime": "low|normal|elevated|high",
           "key_insights": ["insight 1", "insight 2", ...]
       }
       """
       return await agent.run(research_prompt)
   ```

   **Turn 2: Ideation Phase**:
   ```python
   async def _ideation_phase(self, research: dict, agent) -> List[dict]:
       """Phase 2: Generate 5 diverse strategy ideas (not full Strategy objects)."""
       ideation_prompt = f"""Based on research: {research}

       Generate 5 diverse strategy IDEAS (not full implementations).

       For each idea, provide:
       - name: Strategy name
       - thesis: Investment thesis (2-3 sentences)
       - edge_type: behavioral/structural/informational/risk_premium
       - archetype: momentum/mean_reversion/carry/directional/volatility

       Return: List[dict] with these 4 fields only.
       """
       return await agent.run(ideation_prompt)
   ```

   **Turn 3: Edge Articulation Phase** (iterate over 5 ideas):
   ```python
   async def _articulate_edge(self, idea: dict, research: dict, agent) -> Strategy:
       """Phase 3: Develop full strategy from idea."""
       articulation_prompt = f"""Develop this strategy idea into a full Strategy.

       Idea: {idea}
       Research: {research}

       Provide:
       1. thesis: Clear, falsifiable investment thesis (min 100 chars)
       2. edge_explanation: Why this edge exists and persists (min 100 chars)
       3. why_now: Regime fit citing research data (min 50 chars)
       4. failure_modes: List of specific conditions that break thesis (min 1)
       5. expected_behavior: How strategy performs in different regimes
       6. assets: Ticker list
       7. weights: Allocation dict
       8. rebalance_frequency: daily/weekly/monthly/quarterly

       Return: Complete Strategy object.
       """
       return await agent.run(articulation_prompt)
   ```

   **Turn 4: Diversity Check**:
   ```python
   async def _diversity_check(self, candidates: List[Strategy], agent) -> None:
       """Phase 4: Validate diversity across candidates."""
       # Check diversity dimensions, regenerate if needed
   ```

4. **Update Prompts**:
   - Update `candidate_generation_system.md` OUTPUT CONTRACT (lines 285-300) to show new Strategy fields
   - Update `candidate_generation.md` worked examples (lines 160-239) to demonstrate new fields
   - Shorten prompts by removing redundant sections (move to multi-turn conversation)

5. **Update Edge Scorer Serialization** (`edge_scorer.py:66-82`):
   ```python
   strategy_json = {
       "name": strategy.name,
       "thesis": strategy.thesis,  # ✅ Now available
       "edge_explanation": strategy.edge_explanation,  # ✅ Now available
       "edge_type": strategy.edge_type.value,  # ✅ Now available
       "why_now": strategy.why_now,  # ✅ Now available
       "archetype": strategy.archetype.value,  # ✅ Now available
       "failure_modes": strategy.failure_modes,  # ✅ Now available
       "expected_behavior": strategy.expected_behavior,  # ✅ Now available
       "assets": strategy.assets,
       "weights": strategy.weights,
       "rebalance_frequency": strategy.rebalance_frequency.value,
       "logic_tree": strategy.logic_tree
   }
   ```

6. **Update All Tests**:
   - Update fixtures in `tests/agent/` to include new required fields
   - Add validation tests for new field validators

**Pros**:
- **Fixes root cause**: Captures all reasoning demanded by prompts
- **Research-backed**: Field ordering (60% improvement), multi-turn (Kimi K2 optimized)
- **Comprehensive**: Edge scorer receives all needed information
- **Explicit validation**: Field validators prevent placeholder text
- **Backward compatible path**: Can migrate gradually

**Cons**:
- **High implementation effort**: Touches 8+ files (models, generator, scorer, prompts, tests)
- **Breaking change**: All existing test fixtures need updates
- **More tokens**: Richer outputs = higher token costs
- **Still model-dependent**: Kimi K2 may lack strategic depth even with better structure

**Risk Level**: Medium
- Technical risk: Low (well-defined changes)
- Effort risk: High (extensive updates needed)
- Outcome risk: Medium (depends on Kimi K2 capabilities)

**Estimated Effort**: 4-6 hours
- Models update: 1 hour
- Multi-turn workflow: 2 hours
- Prompt updates: 1 hour
- Test fixture updates: 1-2 hours

---

### Solution B: Two-Stage Generation (Free-Form → Structured)

**Philosophy**: Separate reasoning from structure. First generate free-form strategic documents, then extract structured data in a second pass.

**Implementation Path**:

1. **Create StrategyProposal Model** (intermediate format):
   ```python
   class StrategyProposal(BaseModel):
       """Free-form strategy proposal with rich reasoning."""
       name: str
       thesis_document: str = Field(..., min_length=500, description="Comprehensive thesis in free-form prose")
       edge_analysis: str = Field(..., min_length=300)
       risk_assessment: str = Field(..., min_length=200)
       regime_fit: str = Field(..., min_length=150)
       # No strict structure - allows LLM to reason freely
   ```

2. **Two-Stage Workflow**:

   **Stage 1: Generate Free-Form Proposals**:
   ```python
   async def _generate_proposals(self, market_context: dict, agent) -> List[StrategyProposal]:
       """Generate 5 rich strategy proposals without execution constraints."""
       proposal_prompt = """Generate 5 diverse trading strategy proposals.

       For each, write a comprehensive strategy document:

       1. thesis_document:
          - What is the investment thesis? (3-5 paragraphs)
          - What causal mechanism drives returns?
          - What are falsifiable conditions?

       2. edge_analysis:
          - What specific inefficiency is exploited?
          - Why does this edge exist? (behavioral/structural/informational/risk premium)
          - Why hasn't it been arbitraged away?
          - What are capacity limits?

       3. risk_assessment:
          - What are specific failure modes with triggers?
          - What is max tolerable drawdown?
          - What is risk-adjusted return expectation (target Sharpe)?

       4. regime_fit:
          - How does this align with current regime?
          - What happens if regime shifts?

       Write in free-form prose. Be comprehensive. No need to specify assets yet.

       Return: List[StrategyProposal]
       """
       return await agent.run(proposal_prompt, output_type=List[StrategyProposal])
   ```

   **Stage 2: Extract Structured Strategies**:
   ```python
   async def _extract_strategy(self, proposal: StrategyProposal, agent) -> Strategy:
       """Convert free-form proposal to structured Strategy."""
       extraction_prompt = f"""Convert this strategy proposal to a structured Strategy.

       Proposal: {proposal.model_dump_json(indent=2)}

       Extract:
       - thesis: 2-3 sentence summary of thesis_document
       - edge_explanation: 2-3 sentence summary of edge_analysis
       - edge_type: Classify as behavioral/structural/informational/risk_premium
       - archetype: Classify as momentum/mean_reversion/carry/directional/volatility
       - failure_modes: Extract specific failure conditions as list
       - why_now: Extract regime fit reasoning
       - expected_behavior: Extract from risk_assessment

       Then specify:
       - name: Concise strategy name
       - assets: Ticker list implementing this thesis
       - weights: Allocation dict
       - rebalance_frequency: Appropriate frequency

       Return: Complete Strategy object.
       """
       return await agent.run(extraction_prompt, output_type=Strategy)
   ```

3. **Validation Between Stages**:
   - Score proposals using a "ProposalScorer" before extraction
   - Only extract high-quality proposals (ensures garbage-in doesn't become garbage-out)
   - Can iterate on proposals before committing to execution details

**Pros**:
- **Separates concerns**: Reasoning unconstrained by schema
- **Research-backed**: "Two-stage process for quality" (Instill AI)
- **Higher quality reasoning**: LLM not distracted by schema compliance during thinking
- **Validation gate**: Can score/filter proposals before extraction
- **Cleaner prompts**: Stage 1 focuses on reasoning, Stage 2 on structure

**Cons**:
- **2x token costs**: Two LLM calls per strategy (10 total for 5 strategies)
- **More complex workflow**: Two models, two validation steps
- **Extraction risk**: Stage 2 might lose nuance from Stage 1
- **Longer latency**: Sequential calls increase total time
- **Still requires Schema Extension**: Solution A's model changes still needed

**Risk Level**: Medium-High
- Technical risk: Medium (more complex pipeline)
- Effort risk: High (new models + 2-stage orchestration)
- Outcome risk: Medium (extraction quality uncertain)
- Cost risk: High (2x token usage)

**Estimated Effort**: 5-7 hours
- StrategyProposal model: 1 hour
- Two-stage workflow: 3 hours
- Proposal scorer: 1 hour
- Extraction validation: 1 hour
- Test updates: 1-2 hours

---

### Solution C: Model Migration + Simplified Prompts

**Philosophy**: The problem isn't just the schema - it's using the wrong model for the task. Migrate to GPT-4o (known for instruction following) and radically simplify prompts to fight attention degradation.

**Implementation Path**:

1. **Keep Current Schema Short-Term**:
   - Don't extend Strategy model yet
   - Focus on getting ANY model to follow existing prompts

2. **Migrate to GPT-4o** (or Claude 3.5 Sonnet):
   - Change `DEFAULT_MODEL` from `openai:kimi-k2-0905-preview` to `openai:gpt-4o`
   - GPT-4o has better instruction following and doesn't have Kimi K2's one-shot limitations
   - Claude 3.5 Sonnet has even better strategic reasoning capabilities

3. **Radically Simplify Prompts** (attack attention degradation):

   **Before** (782 lines):
   - System: 421 lines (candidate_generation_system.md)
   - Recipe: 361 lines (candidate_generation.md)
   - Total: 782 lines, ~6,500 tokens

   **After** (target: <300 lines, ~2,500 tokens):
   - Consolidate into single focused prompt
   - Remove redundant sections
   - Focus on core requirements only
   - Move examples to few-shot in user prompt instead of system prompt

4. **Distilled Prompt Example**:
   ```markdown
   # Trading Strategy Generation

   Generate 5 diverse trading strategies for a 90-day evaluation period.

   ## Core Requirements (Non-Negotiable)

   Each strategy MUST include:

   1. **Investment Thesis** (2-3 sentences):
      - What specific inefficiency are you exploiting?
      - Why does this edge exist? (causal mechanism)
      - What would falsify your thesis? (specific triggers)

   2. **Edge Economics**:
      - Edge type: behavioral | structural | informational | risk_premium
      - Why hasn't this been arbitraged away?

   3. **Risk Framework**:
      - Failure modes: List 2-3 specific conditions that break the strategy
      - Max tolerable drawdown: X%
      - Target Sharpe ratio: Y

   4. **Execution Details**:
      - Assets: Ticker list
      - Weights: Allocation dict (must sum to 1.0)
      - Rebalance frequency: daily|weekly|monthly|quarterly

   5. **Regime Fit**:
      - Current regime: {market_context.regime_tags}
      - Why now: How does your thesis fit current conditions?

   ## Diversity Mandate

   Your 5 strategies MUST have:
   - At least 3 different edge types
   - At least 3 different archetypes (momentum/mean reversion/carry/directional/volatility)
   - Mix of concentrated (≤5 assets) and diversified (≥10 assets)

   ## Market Context

   {market_context_json}

   ## Output Format

   Return: List[Strategy] with exactly 5 strategies.

   Each Strategy must have all required fields populated with thoughtful, specific content.
   Minimal or placeholder values will be rejected.
   ```

5. **Add Aggressive Validation**:
   ```python
   @field_validator('thesis')
   @classmethod
   def validate_thesis_quality(cls, v: str) -> str:
       """Enforce thesis quality at schema level."""
       if len(v) < 100:
           raise ValueError("Thesis must be at least 100 characters (2-3 sentences)")

       # Check for generic phrases
       generic_phrases = [
           "buy winners", "diversify", "follow trends",
           "momentum works", "mean reversion", "stocks go up"
       ]
       if any(phrase in v.lower() for phrase in generic_phrases):
           raise ValueError(f"Thesis too generic. Must articulate specific inefficiency.")

       return v
   ```

6. **Test with Multiple Models**:
   - Run same workflow with GPT-4o, Claude 3.5 Sonnet, Kimi K2
   - Compare thesis quality and edge scoring pass rates
   - Choose best-performing model

**Pros**:
- **Fastest to implement**: Just change model + simplify prompts (2-3 hours)
- **Addresses attention degradation**: Shorter prompts = better focus
- **GPT-4o proven**: Known for strong instruction following
- **Lower risk**: Can revert easily if doesn't work
- **Could reveal if problem is model, not schema**: Diagnostic value

**Cons**:
- **Doesn't fix structural issue**: Strategy model still lacks reasoning fields
- **Still type-driven loss**: Even with better prompts, schema filter remains
- **May not be sufficient**: If root cause is schema mismatch, model swap won't fix it
- **Cost**: GPT-4o more expensive than Kimi K2 (~3-4x)
- **Band-aid solution**: Treats symptoms, not root cause

**Risk Level**: Low-Medium
- Technical risk: Low (simple changes)
- Effort risk: Low (quick to implement)
- Outcome risk: High (may not solve structural problem)
- Cost risk: Medium (higher per-run costs)

**Estimated Effort**: 2-3 hours
- Prompt consolidation: 1-2 hours
- Model testing: 1 hour
- Validation tuning: 30 minutes

---

## Comparative Analysis

| Criteria | Solution A: Schema Extension + Multi-Turn | Solution B: Two-Stage Free-Form → Structured | Solution C: Model Migration + Simplified Prompts |
|----------|------------------------------------------|---------------------------------------------|------------------------------------------------|
| **Fixes Root Cause** | ✅ Yes - captures all reasoning | ⚠️ Partial - still needs schema extension | ❌ No - structural mismatch remains |
| **Research-Backed** | ✅ Yes - field ordering (60%), multi-turn | ✅ Yes - two-stage quality improvement | ⚠️ Partial - shorter prompts help |
| **Implementation Effort** | High (4-6 hours) | High (5-7 hours) | Low (2-3 hours) |
| **Token Costs** | Medium (richer outputs) | High (2x LLM calls) | Medium-High (GPT-4o 3-4x cost) |
| **Risk Level** | Medium | Medium-High | Low-Medium |
| **Backward Compatibility** | ❌ Breaking change | ❌ New models needed | ✅ Mostly compatible |
| **Scalability** | ✅ Good - cleaner architecture | ⚠️ Complex - 2-stage pipeline | ✅ Good - simpler prompts |
| **Quality Ceiling** | High (comprehensive reasoning) | High (unconstrained reasoning) | Medium (still limited by schema) |
| **Time to Validate** | Medium (need full implementation) | High (need both stages) | Low (can test quickly) |
| **Kimi K2 Specific** | ✅ Multi-turn optimized for Kimi K2 | ⚠️ Doesn't address Kimi K2 limits | ✅ Bypasses Kimi K2 by switching models |
| **Edge Scorer Fix** | ✅ Complete - all data available | ✅ Complete - all data available | ❌ Incomplete - still missing fields |

---

## Recommendations

### **Primary Recommendation: Solution A (Schema Extension + Multi-Turn Workflow)**

**Reasoning**:
1. **Only solution that fully fixes root cause**: Extends Strategy model to capture reasoning, eliminating type-driven information loss
2. **Research-backed techniques**: Combines field ordering (60% improvement), multi-turn workflow (Kimi K2 optimized), and explicit validation
3. **Comprehensive edge scorer fix**: Edge scorer receives all thesis/edge/risk data needed for evaluation
4. **Long-term architecture**: Cleaner separation of concerns (research → ideation → articulation → diversity check)
5. **Sustainable**: Once implemented, workflow is more maintainable and extensible

**Phased Implementation Plan**:

**Phase 1: Schema Extension** (Priority 1, 2 hours)
1. Add new fields to Strategy model with field ordering (reasoning FIRST)
2. Add EdgeType and StrategyArchetype enums
3. Add field validators for substantive content
4. Update edge_scorer.py serialization to include new fields

**Phase 2: Multi-Turn Workflow** (Priority 2, 3 hours)
1. Break candidate_generator.py into 4 phases (research, ideation, articulation, diversity check)
2. Update prompts to be phase-specific and shorter
3. Add intermediate validation between phases

**Phase 3: Test Updates** (Priority 3, 2 hours)
1. Update all test fixtures with new required fields
2. Add tests for field validators
3. Update integration tests

**Phase 4: Validation** (Priority 4, 1 hour)
1. Run full workflow end-to-end
2. Verify edge scoring passes with new data
3. Compare token costs before/after

**Total Estimated Time**: 8 hours (spread over 1-2 days)

---

### **Alternative: Hybrid Approach (Solution C → Solution A)**

If you want to **validate quickly before committing**:

**Step 1: Test with GPT-4o** (2-3 hours)
- Switch to GPT-4o with simplified prompts
- See if better model + shorter prompts improve output quality
- **If it works**: Confirms problem is model/prompt length, not schema
- **If it doesn't work**: Confirms structural schema mismatch is root cause

**Step 2: Implement Solution A** (4-6 hours)
- Regardless of Step 1 results, implement schema extension
- Use learnings from Step 1 to inform prompt design

**Why this works**:
- Low-risk diagnostic (Step 1) before high-effort fix (Step 2)
- Even if GPT-4o helps, schema extension still needed for long-term quality
- You get faster feedback loop (can test within hours instead of days)

---

### **Not Recommended: Solution B (Two-Stage)**

**Reasoning**:
- Still requires Schema Extension (same work as Solution A)
- Adds complexity (2-stage pipeline, proposal scorer)
- 2x token costs with uncertain benefit
- Extraction stage might lose nuance
- No clear advantage over Solution A

**Only consider if**:
- Token costs are not a concern
- You want maximum reasoning quality regardless of complexity
- You plan to use proposals for other purposes (e.g., human review before execution)

---

## Next Steps

### Immediate Actions

1. **Decision Point**: Choose implementation approach
   - Recommended: Solution A (Schema Extension + Multi-Turn)
   - Alternative: Hybrid (Test GPT-4o first, then Solution A)

2. **Create Implementation Branch**:
   ```bash
   git checkout -b fix/candidate-generation-schema-extension
   ```

3. **Start with Schema** (Phase 1):
   - Update `src/agent/models.py` with new Strategy fields
   - Add enums for EdgeType and StrategyArchetype
   - Add field validators

4. **Validate Schema** (quick test):
   - Manually create a Strategy with new fields
   - Verify edge_scorer can serialize and score it
   - Confirms schema changes work before workflow changes

5. **Implement Multi-Turn** (Phase 2):
   - Update `candidate_generator.py` with phased approach
   - Shorten and focus prompts for each phase

6. **Test End-to-End** (Phase 4):
   - Run integration test with real market context
   - Verify strategies pass edge scoring (all dimensions ≥3)

### Success Metrics

**Before Fix**:
- Edge Scorecard: 2/1/2/3/3 (FAIL - 3 dimensions below threshold)
- Generated output: Bare assets/weights only
- Thesis quality: "No thesis articulated"

**After Fix (Target)**:
- Edge Scorecard: ≥3/≥3/≥3/≥3/≥3 (PASS - all dimensions meet threshold)
- Generated output: Complete Strategy with thesis, edge, failure_modes
- Thesis quality: "Clear thesis with causal reasoning and falsifiable conditions"

**Measurement**:
1. Run test: `./venv/bin/pytest tests/agent/test_phase5_integration.py::TestPhase5EndToEnd::test_full_workflow_with_real_context_and_mcps -v -m integration -s`
2. Check edge scorecard scores in output
3. Inspect generated strategies for completeness

---

## References

### Code References

- `src/agent/stages/candidate_generator.py:107` - output_type constraint
- `src/agent/models.py:29-113` - Strategy model definition (missing fields)
- `src/agent/stages/edge_scorer.py:66-72` - Strategy serialization (incomplete)
- `src/agent/prompts/system/candidate_generation_system.md:106-113` - Edge articulation requirements
- `src/agent/prompts/candidate_generation.md:111-131` - Edge template
- `src/agent/prompts/edge_scoring.md:32-274` - Scoring dimensions requiring missing data

### Research Sources

**LLM Prompt Adherence**:
- "Same Task, More Tokens: Impact of Input Length on Reasoning Performance" - Attention degradation at 3,000 tokens
- MLOps Community - "The Impact of Prompt Bloat on LLM Output Quality" - Lost in the middle effect
- Stack Overflow - "Why does structured output ignore optional params in Pydantic models" - Minimum field compliance

**Field Ordering**:
- Dylan Castillo - "Say What You Mean (Sometimes)" - 60% improvement with reasoning fields first
- dsdev.in - "Order of fields in structured output can hurt LLMs" - Sequential generation importance

**Kimi K2 Specific**:
- DataCamp - "Kimi K2 Tutorial" - One-shot prompting degradation, agentic workflows recommended
- Hugging Face - "moonshotai/Kimi-K2-Instruct" - Temperature = 0.6 recommendation
- grapeot.me - "Kimi K2 Analysis" - Depth-of-thought limitations

**Structured Output**:
- Instill AI - "LLM Structured Outputs" - Two-stage process for quality
- Towards Data Science - "Diving Deeper with Structured Outputs" - Reasoning field 60% accuracy boost
- ai.pydantic.dev - "Output Modes" - Instruction mode least reliable

### Git Context

- Current branch: main
- Commit: 0c7633584f35350c05b170ac854a84ea5699cee8
- Status: Unstaged changes in candidate_generator.py, edge_scorer.py, mcp_config.py, workflow.py

---

## Appendix: Example of Fixed Strategy Output

**Current Output** (fails validation):
```python
Strategy(
    name='Growth Momentum Leaders',
    assets=['XLK', 'XLY', 'XLV'],
    weights={'XLK': 0.45, 'XLY': 0.35, 'XLV': 0.2},
    rebalance_frequency='monthly',
    logic_tree={}
)
# ❌ Edge scorer receives: just tickers and weights
# ❌ Cannot evaluate thesis, edge, or risk framework
```

**Target Output After Fix** (passes validation):
```python
Strategy(
    # Reasoning fields FIRST
    thesis="Technology and consumer discretionary sectors exhibit persistent momentum due to AI infrastructure investment cycle (hyperscaler Q4 capex guidance up 40% YoY) and strong consumer spending (retail sales +3.8% YoY). Healthcare provides defensive balance. Thesis falsifies if: (1) tech capex guidance cuts >15% in next earnings, (2) consumer confidence index drops below 95, or (3) sector correlation exceeds 0.85 indicating diversification breakdown.",

    edge_explanation="Momentum persistence in sector rotation driven by institutional capital flow lags. Large asset managers rebalance quarterly (calendar constraints) creating 2-4 week windows where sector trends continue post-identification. Edge exists due to: (1) structural rebalancing constraints, (2) behavioral under-reaction to sector earnings surprises in mid-caps. Persists because front-running quarterly flows requires market impact costs exceeding edge for AUM >$100M.",

    edge_type=EdgeType.STRUCTURAL,

    why_now="Current regime (strong_bull + growth_favored + volatility_low per context pack) shows VIX at 18.6 (normal range), market breadth 68% (strong), and tech sector +22% vs SPY +15% over 90d. Low volatility environment enables momentum strategies; high breadth confirms broad participation not narrow speculation. Q4 earnings catalyst timing (Jan-Feb) fits 90-day evaluation window.",

    archetype=StrategyArchetype.MOMENTUM,

    failure_modes=[
        "VIX spike >28 for 5+ consecutive days triggers defensive rotation, expect -12% to -18% drawdown",
        "Sector correlation >0.85 indicates false diversification, invalidates multi-sector thesis",
        "Tech earnings miss >10% (MSFT, AAPL, GOOGL) triggers sector rotation to value, expect -15% drawdown",
        "Fed emergency rate cut signals recession, momentum reverses to mean reversion regime"
    ],

    expected_behavior="Bull continuation: +18% to +25% (target 1.4 Sharpe). Volatility spike: -12% to -18% (no dynamic hedge). Sector rotation to value: -8% to -12% (healthcare provides partial offset). Range-bound market: +3% to +8% (momentum decay, rebalancing costs erode gains).",

    # THEN execution fields
    name='Tech-Consumer Momentum with Healthcare Balance',
    assets=['XLK', 'XLY', 'XLV'],
    weights={'XLK': 0.45, 'XLY': 0.35, 'XLV': 0.2},
    rebalance_frequency=RebalanceFrequency.MONTHLY,
    logic_tree={}
)
# ✅ Edge scorer receives: complete thesis, edge reasoning, failure modes
# ✅ Can properly evaluate all 5 dimensions
```

---

*Generated by APEX Research Intelligence System*
*Research ID: candidate-generation-fix | Confidence: 9/10 | Sources: 3 parallel agents + 15 web research sources*
