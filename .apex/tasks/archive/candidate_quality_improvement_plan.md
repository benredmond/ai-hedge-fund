# Candidate Quality Improvement Plan

**Created**: 2025-11-05
**Status**: Planning
**Goal**: Fix candidate generation producing low-quality strategies

---

## Executive Summary

The AI hedge fund candidate generation currently produces low-quality strategies with 5 critical flaws:

1. **Implementation Incoherence**: Thesis describes "dynamic rotation" but weights are static
2. **Unfalsifiable Claims**: "Behavioral biases" without evidence or citations
3. **Missing Quantification**: No Sharpe targets, alpha estimates, or drawdown expectations
4. **Concentration Risk**: 75% allocation in 3 correlated semiconductor stocks
5. **Technical Confusion**: RSI (mean-reversion oscillator) used for momentum strategy

This document synthesizes solutions from:
- Parallel brainstorming (4 expert perspectives: Schema, Prompt, Quant, Validation)
- Existing documentation (prompt_engineering_architecture_plan.md, prompt_engineering_analysis_nov2024.md)

---

## Problem Analysis

### Example Current Output

```python
Strategy(
  name='Semiconductor Momentum Rotation Strategy',
  thesis_document="""
    The semiconductor industry exhibits strong momentum characteristics driven by
    cyclical demand patterns, technological innovation cycles, and investor sentiment
    swings. This strategy exploits behavioral biases that cause investors to underreact
    to positive earnings momentum in semiconductor stocks while overreacting to
    short-term volatility. The 20-day RSI filter identifies stocks with strong price
    momentum that haven't reached extreme overbought levels, capturing the sweet spot
    of trend continuation.
  """,
  edge_type='behavioral',
  archetype='momentum',
  assets=['NVDA', 'AMD', 'AVGO', 'VYM', 'SCHD'],
  logic_tree={'type': 'momentum_filter', 'criteria': '20-day RSI top 2 semiconductors',
              'fallback': 'dividend ETFs', 'condition': 'if semiconductor momentum > threshold'},
  weights={'NVDA': 0.25, 'AMD': 0.25, 'AVGO': 0.25, 'VYM': 0.125, 'SCHD': 0.125},
  rebalance_frequency='quarterly'
)
```

### Critical Quality Issues

| Issue | Manifestation | Impact |
|-------|--------------|--------|
| **Implementation Incoherence** | Thesis says "dynamic rotation based on RSI" but weights are fixed 25/25/25/12.5/12.5 | Strategy won't execute as described |
| **Unfalsifiable Claims** | "Behavioral biases cause underreaction" - no citation, no measurement | Can't validate or test edge |
| **Missing Quantification** | No expected Sharpe, alpha, or drawdown | Can't evaluate success/failure |
| **Concentration Risk** | 75% in 3 semiconductor stocks (correlation ~0.7-0.8) | Catastrophic sector-specific risk |
| **Technical Confusion** | RSI (oscillator, mean-reverts) for momentum (trends) | Conceptual mismatch - wrong indicator |
| **Edge-Frequency Violation** | Momentum + Quarterly rebalancing | Explicitly forbidden in AUTO-REJECT matrix |

---

## Brainstorming Results (4 Perspectives)

### 1. Schema Design Perspective

**Focus**: Prevent quality issues at data model level

**Top Solutions**:
1. **Discriminated Union for Static vs Dynamic** - Make static/dynamic mutually exclusive types
2. **Structured LogicTreeNode** - Replace `Dict[str, Any]` with validated Pydantic model
3. **Required Evidence Citations** - Force structured citations (research_paper/backtest/hypothesis)
4. **Quantitative Expectations Schema** - Require Sharpe, alpha, drawdown fields
5. **Risk Concentration Limits** - Schema-level bounds (max 40% single asset, 75% sector)
6. **Archetype-Constrained Rebalancing** - Encode edge-frequency matrix in validators
7. **Mandatory Rebalancing Rationale** - Regex validation for weight derivation keywords
8. **Failure Modes with Testable Conditions** - Structured FailureMode type

**Effectiveness**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (prevents entire classes of errors)
**Complexity**: High (requires schema migration)
**Time**: 8-12 hours

### 2. Prompt Engineering Perspective

**Focus**: Guide LLM to produce quality through instruction design

**Top Solutions**:
1. **Forced Quantification Table** (pre-generation) - Require numeric estimates before ideation
2. **Implementation Syntax Checker** (post-generation) - Validate logic_tree structure
3. **Anti-Pattern Gallery** - Show BAD vs GOOD examples contrastively
4. **Two-Pass Generation** - Write thesis first, derive implementation second
5. **Socratic Self-Interrogation** - Force adversarial self-questioning
6. **Constraint Tightening** - Hard bounds on all parameters (Sharpe 0.5-2.0, DD 8-30%)
7. **Example Ablation** - Test if removing examples improves reasoning
8. **Chain-of-Thought Scaffolding** - Explicit reasoning steps before code

**Effectiveness**: ‚≠ê‚≠ê‚≠ê‚≠ê (improves quality without code changes)
**Complexity**: Medium (prompt engineering only)
**Time**: 4-6 hours

### 3. Quantitative Strategy Perspective

**Focus**: Enforce standards a PM would demand

**Top Solutions**:
1. **Edge Falsifiability Test** - Require observable metrics + thresholds + outcomes
2. **Technical Indicator Coherence** - Validate indicators match archetype (no RSI for momentum)
3. **Performance Quantification** - Mandate Sharpe vs benchmark or return differential
4. **Benchmark Comparison** - Force "Why not just buy SPY?" explanation
5. **Concentration Risk Limits** - Flag correlation >0.8 as false diversification
6. **Overfitting Heuristics** - Detect overly precise parameters (23.47% thresholds)
7. **Research Citation Requirement** - Behavioral edges need academic support
8. **Backtest Evidence Standard** - Historical claims need timeframe + sample size
9. **Failure Mode Specificity** - Require numeric triggers and impact estimates
10. **PM Approval Checklist** - 5 fundamental questions (elevator pitch, observability, conviction)

**Effectiveness**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (prevents hand-waving)
**Complexity**: Medium (validation functions)
**Time**: 6-8 hours

### 4. Validation Pipeline Perspective

**Focus**: Build quality gates into workflow

**Top Solutions**:
1. **Edge-Frequency Coherence Enforcer** (pre-generation) - Block before strategy created
2. **Quantification Requirement Gate** - Reject thesis without numeric expectations
3. **Logic Tree Complexity Analyzer** - Measure branches, depth, cyclomatic complexity
4. **Concentration Risk Validator** - Automated correlation matrix checks
5. **Thesis-Logic Gap Detector** (LLM-based) - Semantic consistency validation
6. **Quality Score Aggregator** - Weighted scoring (quantification 25%, coherence 30%, complexity 20%)
7. **Retry Budget with Escalating Guidance** - 3 attempts with increasingly specific feedback
8. **Pre-Backtest Sanity Checks** - Fast heuristics before expensive API calls

**Effectiveness**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (systematic quality control)
**Complexity**: High (orchestration logic)
**Time**: 8-10 hours

---

## Document Comparison Findings

### Solutions Already in Existing Docs ‚úÖ

1. **Two-Pass Generation** ‚Üí Docs call it "Planning Matrix" (architecture_plan.md Fix #3)
2. **Forced Quantification** ‚Üí Docs have "Backtesting Validation Requirement" (Fix #5)
3. **Retry Mechanism** ‚Üí Docs specify "Surgical Retry with Asset Preservation"
4. **Edge-Frequency Alignment** ‚Üí Docs have AUTO-REJECT matrix
5. **Thesis-Logic Coherence** ‚Üí Docs validate conditional keywords ‚Üí logic_tree

### Novel Contributions from Brainstorming üÜï

1. **Risk Concentration Limits with Numeric Thresholds** - Max 40% asset, 75% sector
2. **Implementation Syntax Checker** - Programmatic validation (weights sum, structure)
3. **Quality Score Aggregator** - Weighted scoring for retry decisions
4. **Pre-Generation Enforcers** - Block generation vs post-generation retry
5. **Overfitting Heuristics** - Specific red flags (Sharpe >5, <5 rebalances)

### Critical Gaps (Brainstorming MISSED from Docs) ‚ö†Ô∏è

1. **Constitutional Constraints Layer** - AUTO-REJECT rules at TOP of prompt (priority window for Kimi K2)
2. **Surgical Retry with Asset Preservation** - Prevents "asset drift" ([XLK, XLY, XLF] ‚Üí [XLK, XLV, XLU])
3. **Industry Practice Benchmark** - 40-60% static allocation acceptable (Fama-French, AQR, DFA)
4. **Alpha vs Beta Framework** - Decision matrix for stocks vs sectors by archetype
5. **RSIP 3-Stage Checkpoints** - Pre-generation ‚Üí Post-generation ‚Üí Pre-submission
6. **Historical Archetype Tracking** - Cross-run diversity (track last 5, require 2/5 non-canonical)

### Key Insights

**User Requested**: "Pure prompt engineering" (no Pydantic validators per architecture_plan.md line 24)

**Brainstorming Suggested**: More programmatic validation (schema limits, syntax checkers)

**Recommendation**: Use brainstorming's programmatic validation as **safety net**, not primary enforcement. Docs' prompt patterns are validated.

**Industry Practice**: Forcing 100% conditional logic is over-engineering. Coherence > Complexity.

---

## Recommended Implementation Plan

### Phase 0a: Pre-Implementation Validation (2 hours) üÜï INTELLIGENCE-DRIVEN

**Critical**: Establish baseline before making changes to measure improvement

1. **Baseline Establishment** (1 hour)
   - Run 10 test generations with current prompts
   - Record metrics: avg quality score, validation error rate, token usage, archetype distribution
   - Save to: `data/baselines/pre_improvements.json`
   - **Why**: Without baseline, cannot measure if improvements actually improve quality
   - **Evidence**: Risk analysis shows 6 failure modes - need baseline to detect regressions

2. **Canary Integration Tests** (1 hour)
   - `test_static_strategy_passes_validation()` - Simple 60/40 SPY/AGG should pass
   - `test_token_budget_under_30k()` - Generation stays within 30k token budget
   - `test_concentration_justified_passes()` - 50% allocation with justification allowed
   - `test_nested_logic_tree_valid()` - Hysteresis example from recipe passes
   - **Why**: Currently zero integration tests for 364 lines of validation code
   - **Evidence**: Git Task vBgdE5rye succeeded using incremental validation

**Time**: 2 hours
**Priority**: CRITICAL (prevents regression, enables measurement)

---

### Phase 0b: Blockers (35 min)

**From existing docs** - not discussed in brainstorming but critical:

1. **Edge Scorecard Enforcement** (20 min)
   - Ensure overall_pass=False strategies filtered before winner selection
   - Location: `src/agent/workflow.py`

2. **Charter Truncation Fix** (15 min)
   - Increase max_tokens or add truncation detection/retry
   - Location: `src/agent/stages/charter_generator.py`

### Phase 1: Core Quality Fixes (4-5 hours)

**Combined best ideas from docs + brainstorming**:

#### 1. Constitutional Constraints Layer (60 min) ‚úÖ MODIFIED - GRADUATED ENFORCEMENT

**What**: Move validation rules to TOP of system prompt with GRADUATED enforcement (not all AUTO-REJECT)

**Why**: Kimi K2 bypasses rules unless they appear before generation context. Risk analysis shows 100% rejection rate if all priorities are hard rejects.

**Where**: `src/agent/prompts/system/candidate_generation_system.md` lines 1-95

**Implementation**:
```markdown
# CONSTITUTIONAL CONSTRAINTS - VALIDATION PRIORITY SYSTEM

These rules guide strategy quality. Priorities determine enforcement severity.

## PRIORITY 1: Implementation-Thesis Coherence (HARD REJECT)

**This is the ONLY hard reject rule.**

IF thesis contains conditional keywords: ["if", "when", "rotate", "tactical", "VIX >", "dynamic", "allocate based on"]
‚Üí THEN logic_tree MUST be populated with {condition, if_true, if_false}
‚Üí VIOLATION = AUTO-REJECT

IF thesis contains ranking/selection keywords: ["top", "bottom", "rank", "filter", "select N"]
‚Üí THEN logic_tree MUST use a filter leaf ({filter, assets})
‚Üí VIOLATION = AUTO-REJECT

IF thesis contains static keywords: ["buy-and-hold", "static", "quarterly rebalance ONLY"]
‚Üí THEN logic_tree MUST be empty {}
‚Üí VIOLATION = AUTO-REJECT

**Refined Regex Patterns (contextual matching)**:
- `\bif\s+(vix|breadth|momentum|volatility)\b` (not "if correct")
- `\bwhen\s+(vix|breadth|market)\b` (not "when successful")
- `\brotate\s+to\s+\w+` (not "rotation strategy")

## PRIORITY 2: Edge-Frequency Alignment (RETRY WARNING)

**Not auto-reject - triggers retry with specific fix guidance**

| Edge Type | AVOID Frequencies | Reason | Alternative |
|-----------|------------------|--------|-------------|
| Momentum | Quarterly | Momentum decays 2-4w; quarterly too slow | Weekly/Monthly |
| Mean Reversion | Daily, Weekly | Mean reversion 30-60d; creates whipsaw | Monthly |
| Carry/Dividend | Daily, Weekly, Monthly | High turnover destroys carry | Quarterly |
| Volatility/Tactical | Monthly, Quarterly | Regime shifts require fast response | Daily/Weekly |

**Market regimes may legitimately require exceptions** - retry guidance, not hard block

## PRIORITY 3-4: Weight Derivation & Quantification (SUGGESTIONS)

**Not blocking - warnings with suggestions**

- Round numbers (0.20, 0.25, 0.33, 0.50) without derivation explanation ‚Üí WARNING + hint to add
- Missing quantification (no Sharpe/alpha/drawdown) ‚Üí SUGGESTION to include (not required)

## Concentration Guidelines (with Justification Bypass)

- Max single asset: 40% (50% OK with justification in rebalancing_rationale)
- Max single sector: 75% (100% OK for stock selection strategies with 4+ stocks)
- Min assets: 3 (2 OK if barbell/core-satellite strategy explicitly described)

**Industry Practice**: 40-60% static allocation is acceptable (Fama-French, AQR, DFA)
```

**Time**: 60 min (was 30 min - +30 min for regex refinement and graduated rules)
**Priority**: CRITICAL (prevents 100% rejection rate while maintaining quality)

---

#### 2. Planning Matrix + RSIP Checkpoints (115 min) ‚úÖ MODIFIED - TOKEN OPTIMIZED

**What**: Force pre-generation planning + post-generation reflection with COMPRESSED format

**Why**: Prevents implementation incoherence. Token analysis shows +2,900 tokens per message √ó 20 history = 58k overhead. Compression reduces to +1,300 tokens (55% savings).

**Where**:
- Recipe prompt: `src/agent/prompts/candidate_generation.md` after line 148
- System prompt: `src/agent/prompts/system/candidate_generation_system.md` lines 95-150 (RSIP moved here)

**Implementation**:

**Step 2.0.6: Edge Quantification Schema (COMPRESSED - No Example Row)**
```markdown
BEFORE ideating, define quantitative expectations using this schema:

**Schema**: Edge Type | Expected Sharpe (0.5-2.0) | vs Benchmark (SPY/QQQ/AGG/60-40) | Max DD (-8% to -25%) | Win Rate (45-65%) | Timeframe (90d)

**Constraints:**
- Realistic Sharpe range prevents overfitting signals
- MUST specify benchmark comparison
- Drawdown range prevents "no risk" fantasy
- Win rate prevents "always wins" fantasy

Complete for all 5 candidates before ideating.
```
**Token savings**: 800 ‚Üí 200 tokens (removed example rows)

**Step 2.0.7: Planning Matrix (INLINE Example)**
```markdown
For EACH candidate, plan: Archetype | Conditional? (YES/NO) | Triggers (if YES) | Weight Method | Frequency | Rationale

Example: Momentum | YES | VIX <20 & top 2 sectors by 30d return | Momentum-weighted | Weekly | Momentum persistence 2-4w

**Validation:** All 5 complete, conditional=YES has triggers, frequency aligned with archetype
```
**Token savings**: 600 ‚Üí 300 tokens (inline vs table)

**Step 2.3: RSIP Post-Generation Checklist ‚Üí MOVED TO SYSTEM PROMPT**

**In System Prompt (lines 95-150)**:
```markdown
## RSIP Self-Critique Checklist (Reference from Recipe Step 2.3)

After generating all 5 candidates, verify:

**Priority 1 (HARD REJECT)**: Conditional keywords in thesis ‚Üí logic_tree populated
**Priority 2 (RETRY)**: Edge-frequency alignment (no forbidden combinations)
**Priority 3 (SUGGESTION)**: Quantification present (Sharpe/alpha/drawdown)
**Priority 4 (WARNING)**: Concentration justified if >40% single asset or >75% sector

Create validation summary:
- Candidate #1: [Coherence ‚úÖ/‚ùå] [Frequency ‚úÖ/‚ùå] [Quant ‚úÖ/‚ùå] [Concentration ‚úÖ/‚ùå]
- (repeat for all 5)

If ANY Priority 1 violation ‚Üí Fix before proceeding
```

**In Recipe (Step 2.3)**:
```markdown
**AFTER generating all 5 candidates, complete RSIP Checklist (see system prompt section 2)**

Apply checklist to each strategy and create validation summary table.
Fix Priority 1 violations before proceeding.
```
**Token savings**: 1,500 tokens √ó 20 messages = 30,000 tokens (loaded once in system prompt, not every message)

**Total token savings**: 2,900 ‚Üí 1,300 tokens per message (55% reduction) + 30k from RSIP relocation

**Time**: 115 min (same - compression doesn't change implementation time)
**Priority**: HIGH + CRITICAL for token management

---

#### 3. Surgical Retry Mechanism (90 min) ‚úÖ FROM DOCS

**What**: Retry preserves structure (assets/weights/logic_tree), only revises text

**Why**: November 3 run showed "asset drift" problem

**Where**: `src/agent/stages/candidate_generator.py` lines 409-490

**Implementation**:

```python
async def _retry_failed_strategies(
    self,
    candidates: List[Strategy],
    validation_errors: List[str],
    agent,
    market_context_json: str,
    tracker: TokenTracker
) -> List[Strategy]:
    """
    Surgical retry: preserve assets/weights/logic_tree, only revise thesis.

    CRITICAL: Prevents "asset drift" where retry changes [XLK, XLY, XLF] ‚Üí [XLK, XLV, XLU]
    """
    fix_prompt = self._create_surgical_fix_prompt(validation_errors, candidates)

    retry_prompt = f"""
You generated {len(candidates)} strategies, but validation found issues.

**VALIDATION ERRORS:**
{fix_prompt}

**CRITICAL CONSTRAINTS:**
1. Fix ONLY the thesis_document and rebalancing_rationale text
2. DO NOT modify: assets, weights, logic_tree, rebalance_frequency
3. Return complete List[Strategy] with exactly {len(candidates)} strategies
4. Preserve structure, improve narrative coherence only

**FORBIDDEN CHANGES:**
- ‚ùå Changing asset list [XLK, XLY, XLF] ‚Üí [XLK, XLV, XLU]
- ‚ùå Modifying weights {{"XLK": 0.4}} ‚Üí {{"XLK": 0.5}}
- ‚ùå Altering logic_tree conditions or branches
- ‚ùå Adding/removing strategies (must return {len(candidates)})

**ALLOWED CHANGES:**
- ‚úÖ Revising thesis_document to match implementation
- ‚úÖ Improving rebalancing_rationale clarity
- ‚úÖ Adding quantification (Sharpe, alpha, drawdown estimates)
- ‚úÖ Fixing edge-frequency alignment in narrative
"""

    result = await agent.run(retry_prompt)
    fixed_candidates = result.output

    # CRITICAL: Validate data integrity post-retry
    for i, (original, fixed) in enumerate(zip(candidates, fixed_candidates)):
        if fixed.assets != original.assets:
            raise ValueError(
                f"Retry violated constraint: modified assets for candidate {i}\n"
                f"Original: {original.assets}\n"
                f"Fixed: {fixed.assets}\n"
                f"This is FORBIDDEN - retry must preserve structure."
            )
        if fixed.weights != original.weights:
            raise ValueError(
                f"Retry violated constraint: modified weights for candidate {i}"
            )
        if fixed.logic_tree != original.logic_tree:
            raise ValueError(
                f"Retry violated constraint: modified logic_tree for candidate {i}"
            )

    return fixed_candidates
```

**Time**: 90 min (already in codebase, needs validation strengthening)
**Priority**: HIGH (prevents hallucination during retry)

---

#### 4. Risk Concentration Limits (20 min) üÜï FROM BRAINSTORMING

**What**: Add numeric thresholds to validation

**Why**: Docs mention concentration but lack specific bounds

**Where**: `src/agent/stages/candidate_generator.py::_validate_semantics()`

**Implementation**:

```python
def _validate_concentration(self, strategy: Strategy) -> List[str]:
    """Validate concentration risk limits."""
    errors = []

    # Single asset concentration
    max_weight = max(strategy.weights.values())
    if max_weight > 0.40:
        max_asset = max(strategy.weights, key=strategy.weights.get)
        errors.append(
            f"Priority 4: {strategy.name} - Single asset concentration too high: "
            f"{max_asset} = {max_weight:.0%} > 40% limit. "
            f"Reduce weight or add justification in rebalancing_rationale."
        )

    # Sector concentration (requires yfinance lookup)
    try:
        sector_weights = self._get_sector_weights(strategy.assets, strategy.weights)
        max_sector_weight = max(sector_weights.values())

        if max_sector_weight > 0.75:
            top_sector = max(sector_weights, key=sector_weights.get)
            errors.append(
                f"Priority 4: {strategy.name} - Sector concentration too high: "
                f"{top_sector} = {max_sector_weight:.0%} > 75% limit. "
                f"Current allocation: {sector_weights}. "
                f"Diversify across sectors or justify concentrated sector bet."
            )
    except Exception as e:
        # If sector lookup fails, log warning but don't fail validation
        print(f"[WARNING] Could not validate sector concentration: {e}")

    # Minimum asset count
    if len(strategy.assets) < 3:
        errors.append(
            f"Priority 4: {strategy.name} - Too few assets ({len(strategy.assets)} < 3). "
            f"High-conviction concentrated bets require explicit justification in thesis."
        )

    return errors

def _get_sector_weights(self, assets: List[str], weights: Dict[str, float]) -> Dict[str, float]:
    """Map assets to sectors and aggregate weights."""
    import yfinance as yf

    sector_weights = {}
    for asset in assets:
        try:
            ticker = yf.Ticker(asset)
            sector = ticker.info.get('sector', 'Unknown')
            sector_weights[sector] = sector_weights.get(sector, 0.0) + weights.get(asset, 0.0)
        except:
            sector_weights['Unknown'] = sector_weights.get('Unknown', 0.0) + weights.get(asset, 0.0)

    return sector_weights
```

**Time**: 20 min
**Priority**: MEDIUM (catches current 75% semiconductor issue)

---

#### 5. Implementation Syntax Checker (45 min) üÜï FROM BRAINSTORMING

**What**: Programmatic validation of strategy structure

**Why**: Complements semantic validation with mechanical checks

**Where**: `src/agent/stages/candidate_generator.py::_validate_syntax()`

**Implementation**:

```python
def _validate_syntax(self, strategy: Strategy) -> List[str]:
    """Validate syntactic correctness of strategy structure."""
    errors = []

    # Check 1: Weights sum to 1.0 (¬±0.01 tolerance)
    weight_sum = sum(strategy.weights.values())
    if not 0.99 <= weight_sum <= 1.01:
        errors.append(
            f"Syntax Error: Weights sum to {weight_sum:.4f}, must equal 1.0. "
            f"Current: {strategy.weights}"
        )

    # Check 2: Weights keys match assets
    weight_keys = set(strategy.weights.keys())
    assets_set = set(strategy.assets)
    if weight_keys != assets_set:
        missing = assets_set - weight_keys
        extra = weight_keys - assets_set
        errors.append(
            f"Syntax Error: Weight keys don't match assets. "
            f"Missing weights: {missing}, Extra weights: {extra}"
        )

    # Check 3: Logic tree structure validation (if populated)
    if strategy.logic_tree:
        required_keys = {"condition", "if_true", "if_false"}
        tree_keys = set(strategy.logic_tree.keys())

        is_conditional = required_keys.issubset(tree_keys)
        is_filter_leaf = "filter" in tree_keys and "assets" in tree_keys
        if not (is_conditional or is_filter_leaf):
            missing = required_keys - tree_keys
            errors.append(
                f"Syntax Error: logic_tree missing required keys: {missing}. "
                f"Must have: condition, if_true, if_false OR a filter leaf"
            )

        # Check condition has comparison operator
        condition = strategy.logic_tree.get("condition", "")
        if condition and not any(op in str(condition) for op in [">", "<", ">=", "<=", "==", "!="]):
            errors.append(
                f"Syntax Error: logic_tree condition '{condition}' lacks comparison operator. "
                f"Must include >, <, >=, <=, ==, or !="
            )

    # Check 4: All assets in logic_tree must be in global assets list
    if strategy.logic_tree:
        tree_assets = self._extract_assets_from_logic_tree(strategy.logic_tree)
        if not tree_assets.issubset(assets_set):
            unlisted = tree_assets - assets_set
            errors.append(
                f"Syntax Error: logic_tree references assets not in global list: {unlisted}. "
                f"Add to assets: {strategy.assets}"
            )

    return errors

def _extract_assets_from_logic_tree(self, logic_tree: dict) -> set:
    """Recursively extract all assets mentioned in logic tree."""
    assets = set()

    if isinstance(logic_tree, dict):
        if "assets" in logic_tree:
            assets.update(logic_tree["assets"])
        # Check if_true/if_false branches for asset lists
        for branch in ["if_true", "if_false"]:
            if branch in logic_tree:
                branch_data = logic_tree[branch]
                if isinstance(branch_data, dict):
                    if "assets" in branch_data:
                        assets.update(branch_data["assets"])
                    # Recursive check for nested conditions
                    assets.update(self._extract_assets_from_logic_tree(branch_data))

    return assets
```

**Time**: 45 min
**Priority**: MEDIUM (catches structural errors early)

---

#### 6. Quality Score for Retry Decisions (30 min) üÜï FROM BRAINSTORMING

**What**: Aggregate validation signals into quality score

**Why**: Guide retry intensity (low score = more aggressive feedback)

**Where**: `src/agent/stages/candidate_generator.py`

**Implementation**:

```python
from dataclasses import dataclass

@dataclass
class QualityScore:
    """Aggregate quality metrics for strategy."""
    quantification: float  # 0-1, has Sharpe/alpha/drawdown
    coherence: float       # 0-1, thesis matches implementation
    edge_frequency: float  # 0-1, archetype matches rebalancing
    diversification: float # 0-1, low concentration risk
    syntax: float         # 0-1, structure valid

    @property
    def overall(self) -> float:
        return (
            0.25 * self.quantification +
            0.30 * self.coherence +
            0.20 * self.edge_frequency +
            0.15 * self.diversification +
            0.10 * self.syntax
        )

    @property
    def passes_gate(self) -> bool:
        """Pass if overall >= 0.6 AND no dimension < 0.3"""
        if self.overall < 0.6:
            return False
        return all([
            self.quantification >= 0.3,
            self.coherence >= 0.3,
            self.edge_frequency >= 0.3,
            self.diversification >= 0.3,
            self.syntax >= 0.3,
        ])

def compute_quality_score(self, strategy: Strategy, validation_errors: List[str]) -> QualityScore:
    """Compute quality score from validation results."""

    # Quantification: Check for Sharpe/alpha/drawdown in thesis
    thesis_lower = strategy.thesis_document.lower()
    has_sharpe = "sharpe" in thesis_lower or "sharp ratio" in thesis_lower
    has_alpha = "alpha" in thesis_lower or "vs spy" in thesis_lower or "vs qqq" in thesis_lower
    has_drawdown = "drawdown" in thesis_lower or "dd" in thesis_lower
    quantification = sum([has_sharpe, has_alpha, has_drawdown]) / 3.0

    # Coherence: No Priority 1 errors (thesis-logic mismatch)
    coherence_errors = [e for e in validation_errors if "Priority 1" in e]
    coherence = 1.0 if not coherence_errors else 0.0

    # Edge-Frequency: No Priority 2 errors (archetype-frequency mismatch)
    frequency_errors = [e for e in validation_errors if "Priority 2" in e]
    edge_frequency = 1.0 if not frequency_errors else 0.0

    # Diversification: Based on concentration (inverse of max weight)
    max_weight = max(strategy.weights.values()) if strategy.weights else 1.0
    diversification = 1.0 - min(max_weight, 1.0)

    # Syntax: No syntax errors
    syntax_errors = [e for e in validation_errors if "Syntax Error" in e]
    syntax = 1.0 if not syntax_errors else 0.0

    return QualityScore(
        quantification=quantification,
        coherence=coherence,
        edge_frequency=edge_frequency,
        diversification=diversification,
        syntax=syntax
    )
```

**Update retry logic to use quality score**:

```python
async def generate(self, market_context: dict, model: str) -> List[Strategy]:
    """Generate candidates with quality-based retry."""
    # ... existing generation code ...

    candidates = result.output
    validation_errors = self._validate_semantics(candidates, market_context)

    if validation_errors:
        # Compute quality scores
        quality_scores = [
            self.compute_quality_score(c, [e for e in validation_errors if c.name in e])
            for c in candidates
        ]
        avg_quality = sum(s.overall for s in quality_scores) / len(quality_scores)

        print(f"\n[WARNING] Post-generation validation found {len(validation_errors)} issues")
        print(f"[QUALITY] Average quality score: {avg_quality:.2f}/1.0")

        for i, (candidate, score) in enumerate(zip(candidates, quality_scores), 1):
            print(f"  Candidate {i} ({candidate.name}): {score.overall:.2f}")

        # Escalate feedback based on quality
        if avg_quality < 0.4:
            print("[RETRY] Low quality detected - providing detailed prescriptive guidance")
            # More aggressive retry prompt
        elif avg_quality < 0.6:
            print("[RETRY] Moderate quality - providing specific dimension feedback")
            # Standard retry prompt
        else:
            print("[RETRY] Minor issues - providing targeted fixes only")
            # Light-touch retry prompt

        # ... existing retry code ...
```

**Time**: 30 min
**Priority**: LOW (nice-to-have for retry tuning)

---

### Phase 2: Strategic Sophistication (5-6 hours)

**All from existing docs** - brainstorming missed these:

#### 7. Alpha vs Beta Framework (120 min) ‚úÖ FROM DOCS

**What**: Decision matrix for when stocks vs sectors appropriate by archetype

**Why**: Mean reversion REQUIRES individual stocks; momentum can use ETFs

**Where**: `docs/prompt_engineering_architecture_plan.md` lines 597-606

**Implementation**: Add to prompt as conceptual foundation

**Time**: 120 min
**Priority**: MEDIUM (strategic sophistication)

---

#### 8. Four Archetype Examples (180 min) ‚úÖ FROM DOCS

**What**: Detailed worked examples with conditional logic

**Why**: Analysis shows examples improve conditional logic usage (0% ‚Üí 100%)

**Where**: `src/agent/prompts/candidate_generation.md` lines 458-1023

**Implementation**: Keep existing examples, verify quality

**Time**: 180 min (already implemented)
**Priority**: LOW (already done)

---

#### 9. Historical Archetype Tracking (30 min) ‚úÖ FROM DOCS

**What**: Track last 5 runs, require 2/5 non-canonical archetypes

**Why**: Prevents template convergence (4/5 identical strategies)

**Where**: `src/agent/stages/candidate_generator.py`

**Implementation**: Cross-run diversity enforcement

**Time**: 30 min
**Priority**: LOW (optimization, not blocker)

---

## Implementation Priority Ranking

### Must Do (Phase 0 + Phase 1 Tier 1)

**Total Time: ~3 hours**

1. **Edge Scorecard Enforcement** (20 min) - Phase 0 blocker
2. **Charter Truncation Fix** (15 min) - Phase 0 blocker
3. **Constitutional Constraints Layer** (30 min) - Critical for Kimi K2
4. **Planning Matrix + Quantification Table** (50 min) - Forces quality upfront
5. **RSIP Post-Generation Checklist** (65 min) - Catches errors systematically
6. **Risk Concentration Limits** (20 min) - Catches current 75% semiconductor issue

### Should Do (Phase 1 Tier 2)

**Total Time: ~3 hours**

7. **Surgical Retry Mechanism** (90 min) - Prevents asset drift
8. **Implementation Syntax Checker** (45 min) - Catches structural errors
9. **Quality Score Aggregator** (30 min) - Guides retry intensity

### Nice to Have (Phase 2)

**Total Time: ~5-6 hours**

10. Alpha vs Beta Framework (120 min)
11. Historical Archetype Tracking (30 min)

---

## Success Metrics

### Before Implementation

- ‚ùå Edge-frequency violations: 100% (current example has Momentum + Quarterly)
- ‚ùå Implementation incoherence: 100% (dynamic thesis, static weights)
- ‚ùå Missing quantification: 100% (no Sharpe/alpha/drawdown)
- ‚ùå Concentration risk: 75% single sector
- ‚ö†Ô∏è Average quality score: 0.35/1.0

### After Phase 0 + Phase 1 Tier 1

- ‚úÖ Edge-frequency violations: 0% (hard constraint at schema + prompt level)
- ‚úÖ Implementation incoherence: <10% (planning matrix + RSIP checkpoints)
- ‚úÖ Missing quantification: 0% (mandatory quantification table)
- ‚úÖ Concentration risk: <5% violations (numeric limits enforced)
- ‚úÖ Average quality score: 0.75+/1.0

### After Full Implementation

- ‚úÖ Edge-frequency violations: 0%
- ‚úÖ Implementation incoherence: <5%
- ‚úÖ Missing quantification: 0%
- ‚úÖ Concentration risk: 0%
- ‚úÖ Average quality score: 0.85+/1.0
- ‚úÖ Strategic sophistication: Alpha/Beta framework applied
- ‚úÖ Cross-run diversity: 2/5 non-canonical archetypes

---

## Open Questions

1. **Pure Prompt Engineering vs Programmatic Validation**
   - Docs specify "pure prompt engineering" per user request
   - Brainstorming suggests programmatic layer as safety net
   - **Decision needed**: Add syntax checker + concentration validator or prompt-only?

2. **Pre-Generation vs Post-Generation Enforcement**
   - Docs use post-generation retry (1-2 API calls)
   - Brainstorming suggests pre-generation blocking (potentially 5+ calls)
   - **Decision needed**: Stick with retry approach or add pre-generation gates?

3. **Static vs Conditional Target Rate**
   - Docs: 40-60% static acceptable (industry practice)
   - Brainstorming: Implied 80%+ conditional (discriminated union approach)
   - **Decision needed**: What's the target conditional logic rate?

4. **Example Maximalism vs Minimalism**
   - Docs: Add 4 detailed examples (validated approach)
   - Brainstorming: Test example ablation (minimalist experiment)
   - **Decision needed**: Keep examples or test removal?

---

---

## Phase 3: Professional Investor Standards (5-7 hours) üÜï FROM MULTI-AGENT ANALYSIS

**Context**: 4 independent expert reviews (Investor, Risk Manager, Academic, Execution Trader) of AI-generated strategies revealed critical gaps in professional standards.

**Key Finding**: Strategies scored 2-5/10 deployability despite passing current validation. All agents independently identified same missing elements.

---

### 10. Mandatory Benchmark Comparison (90 min) ‚≠ê CRITICAL

**What**: Force explicit "Why not just buy [simple alternative]?" in thesis

**Why**: **All 4 agents independently flagged "benchmark ignorance" as #1 quality issue**

**Evidence from agent analysis**:
- Investor: "Not a single strategy answered: 'What's my alpha vs the obvious lazy alternative?'"
- Academic: "Market efficiency is the null hypothesis; extraordinary claims need extraordinary evidence"
- Sector Momentum example: Never compared to equal-weight S&P sectors (simpler, lower cost)
- Financial Recovery example: Never compared to XLF (same exposure, 1/10th the cost)

**Where**: `src/agent/prompts/candidate_generation.md` Step 2.0.8 (new)

**Implementation**:

```markdown
## Step 2.0.8: Benchmark Justification (MANDATORY)

For EACH candidate, identify the simplest passive alternative and explain your alpha source:

**Template**:
Strategy Type | Obvious Alternative | Why Alternative Insufficient | Your Alpha Source
-------------|--------------------|-----------------------------|------------------
Sector Rotation | Equal-weight 11 sectors (monthly) | Doesn't capture momentum timing | Momentum persistence 4-8w captured via weekly rebalancing
Stock Selection (Financials) | XLF sector ETF | Indiscriminate; includes weak regionals | Security selection: mega-caps only with fortress balance sheets
VIX Timing | 60/40 static allocation | Misses defensive rotation opportunities | 2-4 day institutional lag when VIX >22

**Validation**:
- IF strategy uses stocks ‚Üí compare to sector ETF (e.g., JPM/BAC/WFC/C vs XLF)
- IF strategy uses sectors ‚Üí compare to SPY or equal-weight sectors
- IF strategy uses factors ‚Üí compare to static factor allocation (e.g., MTUM)
- IF timing/rotation ‚Üí compare to buy-and-hold equivalent

**Required**: Quantify expected alpha vs benchmark (e.g., "+150-200 bps annually vs XLF")
```

**Post-generation validation**:
```python
def _validate_benchmark_comparison(self, strategy: Strategy) -> List[str]:
    """Ensure thesis compares to relevant benchmark."""
    errors = []
    thesis_lower = strategy.thesis_document.lower()

    # Check for benchmark mentions
    benchmarks = ['spy', 'qqq', 'agg', '60/40', 'sector etf', 'xlf', 'xlk', 'smh', 'equal-weight']
    has_benchmark = any(b in thesis_lower for b in benchmarks)

    # Check for alpha quantification
    has_alpha = ('alpha' in thesis_lower or 'vs ' in thesis_lower or 'outperform' in thesis_lower)

    if not has_benchmark:
        errors.append(
            f"Priority 2 (RETRY): {strategy.name} - Missing benchmark comparison. "
            f"Must compare to simplest passive alternative (SPY, sector ETF, etc.) "
            f"and explain why your approach generates alpha."
        )

    if not has_alpha:
        errors.append(
            f"Priority 3 (SUGGESTION): {strategy.name} - Missing alpha quantification. "
            f"Estimate expected outperformance vs benchmark (e.g., '+100-150 bps annually')."
        )

    return errors
```

**Time**: 90 min
**Priority**: ‚≠ê CRITICAL (professional standard, unanimous across agents)

---

### 11. Execution Cost Estimation (75 min) ‚≠ê CRITICAL

**What**: Require turnover estimate and friction budget in thesis

**Why**: **Execution trader showed costs can exceed claimed alpha by 2-10x**

**Evidence from agent analysis**:
- Weekly sector rotation: 15-20% annual friction vs claimed 4% alpha
- Daily VIX rotation: 3-10% friction (high turnover scenario) vs claimed 5% alpha
- Academic: "Transaction costs reduce momentum/reversal profits by 50-70%"

**Real numbers from execution analysis**:

| Strategy | Turnover | Friction | Net Alpha After Costs |
|----------|----------|----------|-----------------------|
| Weekly Sector (at $10M) | 250% | 0.18% | 3.82% (was 4%) ‚úÖ |
| Weekly Sector (at $100M) | 250% | 1.6% | 2.4% (was 4%) ‚ö†Ô∏è |
| Daily VIX (high turnover) | 800% | 3-10% | **-5%** (was 5%) ‚ùå |

**Where**: `src/agent/prompts/candidate_generation.md` Step 2.0.9 (new)

**Implementation**:

```markdown
## Step 2.0.9: Execution Cost Budget (MANDATORY)

For EACH candidate, estimate implementation friction:

**Template**:
Strategy | Rebal Freq | Est. Annual Turnover | Spread Cost (bps) | Impact Cost (bps) | Total Friction | Net Alpha
---------|-----------|---------------------|-------------------|-------------------|----------------|----------
Sector Momentum | Weekly | 250% | 5 bps √ó 250% = 12.5 bps | 10 bps √ó 250% = 25 bps | ~0.4% | 3.6% (4.0% gross - 0.4%)
Financial Recovery | Monthly | 60% | 2 bps √ó 60% = 1.2 bps | 5 bps √ó 60% = 3 bps | ~0.04% | 2.96% (3.0% gross - 0.04%)

**Cost Guidelines**:
- Mega-cap stocks (JPM, AAPL): 1-2 bps spread + 3-5 bps impact
- Sector ETFs (XLK, XLV): 3-5 bps spread + 10-15 bps impact
- Bonds/TLT during stress: 10-20 bps spread + 15-25 bps impact
- Weekly rebalancing: ~50 trades/year
- Daily rebalancing: ~250 trades/year (if triggers hit frequently)

**Stress Multiplier**: Costs increase 3-10x during VIX >30 periods
```

**Post-generation validation**:
```python
def _validate_execution_costs(self, strategy: Strategy) -> List[str]:
    """Validate execution cost awareness."""
    errors = []
    thesis_lower = strategy.thesis_document.lower()
    rationale_lower = strategy.rebalancing_rationale.lower()

    # Check for cost/friction discussion
    cost_keywords = ['turnover', 'friction', 'transaction cost', 'spread', 'slippage', 'impact']
    has_cost_discussion = any(k in thesis_lower or k in rationale_lower for k in cost_keywords)

    # Flag high-frequency strategies without cost analysis
    high_frequency = strategy.rebalance_frequency in ['daily', 'weekly']

    if high_frequency and not has_cost_discussion:
        errors.append(
            f"Priority 2 (RETRY): {strategy.name} - High-frequency rebalancing "
            f"({strategy.rebalance_frequency}) without execution cost analysis. "
            f"Must estimate annual turnover and transaction friction."
        )

    return errors
```

**Time**: 75 min
**Priority**: ‚≠ê CRITICAL (prevents paper returns vs deliverable returns gap)

---

### 12. Capacity Disclosure (45 min) ‚≠ê HIGH

**What**: Estimate max AUM before strategy breaks

**Why**: **Execution trader showed strategies have severe capacity constraints**

**Evidence**:
- VIX rotation: Breaks above $50M (front-running, market impact)
- Weekly sector: Breaks above $250M (becomes the marginal flow)
- Financial recovery: Works to $500M (deeper liquidity in mega-cap stocks)

**Where**: `src/agent/prompts/candidate_generation.md` Step 2.0.10 (new)

**Implementation**:

```markdown
## Step 2.0.10: Capacity Limits (REQUIRED for high-frequency strategies)

Estimate maximum AUM before market impact destroys edge:

**Capacity Guidelines**:
- Daily rebalancing: $10-50M (you become detectable pattern)
- Weekly rebalancing: $50-250M (you move the market)
- Monthly rebalancing: $250M-1B (depends on asset liquidity)
- Individual mega-cap stocks: $500M-1B per name
- Sector ETFs: $100-500M (depends on daily volume)

**Template**:
"This strategy is viable at $10M AUM but degrades above $100M due to [market impact/front-running/pattern detection].
At $1B, execution costs would increase from 0.2% to 2-3%, eliminating alpha."
```

**Time**: 45 min
**Priority**: HIGH (important for production scaling)

---

### 13. Time-Scale Validation (60 min) ‚≠ê HIGH

**What**: Validate claimed edge persistence windows against academic evidence

**Why**: **Academic agent showed multiple strategies had 10-100x wrong time horizons**

**Evidence**:
- Financial Recovery claimed "30-60 day mean reversion" ‚Üí Reality: ETF arbitrage happens in **hours** (Madhavan & Sobczyk 2016)
- VIX strategy claimed "2-4 day institutional lag" ‚Üí Reality: Algorithmic vol-targeting rebalances **intraday**
- Sector Momentum claimed "4-8 week persistence" ‚Üí Academic literature (Moskowitz & Grinblatt 1999): **6-12 months**

**Where**: `src/agent/stages/candidate_generator.py::_validate_edge_timescale()`

**Implementation**:

```python
def _validate_edge_timescale(self, strategy: Strategy) -> List[str]:
    """Validate edge persistence claims against known timescales."""
    errors = []
    thesis_lower = strategy.thesis_document.lower()

    # Known edge timescales from academic literature
    EDGE_TIMESCALES = {
        'etf arbitrage': {'claimed': r'(\d+)-(\d+)\s*day', 'reality': 'hours', 'max_days': 1},
        'momentum': {'claimed': r'(\d+)-(\d+)\s*week', 'reality': '6-12 months', 'min_weeks': 12},
        'mean reversion': {'claimed': r'(\d+)-(\d+)\s*day', 'reality': '1-5 days', 'max_days': 7},
        'institutional lag': {'claimed': r'(\d+)-(\d+)\s*day', 'reality': 'hours to 1 day', 'max_days': 2},
        'vol targeting rebalance': {'claimed': r'(\d+)-(\d+)\s*day', 'reality': 'intraday', 'max_days': 1},
    }

    for edge_type, timescale_info in EDGE_TIMESCALES.items():
        if edge_type in thesis_lower:
            import re
            match = re.search(timescale_info['claimed'], thesis_lower)
            if match:
                claimed_min, claimed_max = int(match.group(1)), int(match.group(2))

                # Check if claimed timescale is realistic
                if 'max_days' in timescale_info and claimed_min > timescale_info['max_days']:
                    errors.append(
                        f"Priority 3 (SUGGESTION): {strategy.name} - Edge timescale may be overstated. "
                        f"Claimed: {claimed_min}-{claimed_max} days for {edge_type}. "
                        f"Academic literature suggests: {timescale_info['reality']}. "
                        f"Verify this edge persists at claimed timescale or adjust thesis."
                    )

    return errors
```

**Time**: 60 min
**Priority**: HIGH (prevents fantasy edge claims)

---

### 14. Devil's Advocate Stage (90 min) ‚≠ê CRITICAL

**What**: Add adversarial review step between candidate generation and winner selection

**Why**: **All 4 agents independently suggested adding self-skepticism**

**Evidence from agent analysis**:
- Investor: "What AI failed to demonstrate: Self-skepticism (never challenged own assumptions)"
- Academic: "Strategy claims edges that would violate semi-strong form market efficiency without sufficient limits to arbitrage"
- Risk Manager: Would ask "What's the realistic worst-case scenario?"
- Me: "Force AI to argue against its own thesis"

**Where**: New stage between Stage 1 (Candidate Gen) and Stage 2 (Edge Scoring)

**Implementation**:

```python
# In src/agent/workflow.py

async def create_strategy_workflow(...):
    # Stage 1: Generate candidates
    candidates = await candidate_gen.generate(...)

    # Stage 1.5: Devil's Advocate Review (NEW)
    print("Stage 1.5/5: Running adversarial review...")
    adversarial_reviews = await run_adversarial_review(candidates, agent, market_context)

    # Attach reviews to candidates for Edge Scorer to consider
    for candidate, review in zip(candidates, adversarial_reviews):
        candidate.adversarial_review = review

    # Stage 2: Edge Scoring (now includes adversarial context)
    scored_candidates = await edge_scorer.score_all(candidates, market_context, ...)
```

**Adversarial review prompt**:

```markdown
# Devil's Advocate Review

You are a skeptical senior portfolio manager reviewing this strategy proposal. Your job is to **find fatal flaws**, not to be supportive.

**Strategy**: {strategy.name}
**Thesis**: {strategy.thesis_document}

**Your task**: For each claim in the thesis, provide adversarial critique:

1. **Edge Validity**: "The claimed edge is X. Why hasn't this been arbitraged away?"
   - Who else is doing this?
   - What prevents competition?
   - Is this edge real or narrative fallacy?

2. **Assumption Challenges**: "The thesis assumes Y. What if the opposite is true?"
   - What if fundamentals justify the valuation?
   - What if correlation ‚Üí1.0 during stress?
   - What if the catalyst doesn't materialize?

3. **Realistic Worst Case**: "The thesis claims Z% max drawdown. What's the 1-in-20 scenario?"
   - 2008 analog: What would have happened?
   - Stress scenario: How bad could it actually get?
   - Hidden correlations during tail events?

4. **Simpler Alternative**: "Why not just buy [benchmark]?"
   - What's the opportunity cost?
   - Is complexity justified by incremental return?

**Output**:
- 3-5 critical questions the strategy must answer
- 2-3 failure scenarios not addressed in thesis
- Risk-adjusted recommendation: Deploy / Pass / Deploy with hedges
```

**Integration with Edge Scorer**:
```python
# In edge_scorer.py prompt, add:

## Adversarial Review Context

Before you score, consider these critical challenges identified by independent review:

{candidate.adversarial_review}

Your scoring should account for whether the thesis adequately addresses these critiques.
If critical challenges are unresolved, penalize thesis_quality and edge_economics scores accordingly.
```

**Time**: 90 min
**Priority**: ‚≠ê CRITICAL (adds self-skepticism AI currently lacks)

---

### 15. Stress Testing Requirement (60 min) ‚≠ê HIGH

**What**: Require testing strategy thesis on 2008, 2020, 2022 regime analogs

**Why**: **Risk officer would demand realistic worst-case scenarios**

**Evidence**:
- Financial Recovery claimed "12-18% max drawdown" but March 2023 bank crisis showed 8-15x cost increase
- Execution trader: "During COVID crash, TLT spreads hit 50-100 bps. Your daily rebalancing = buying at peak"
- All strategies claim comfortable drawdowns (10-20%) without historical validation

**Where**: `src/agent/prompts/candidate_generation.md` Step 2.0.11 (new)

**Implementation**:

```markdown
## Step 2.0.11: Stress Testing (REQUIRED)

For EACH candidate, evaluate thesis under 3 crisis scenarios:

**Scenario 1: 2008 Financial Crisis**
- Correlations ‚Üí 1.0 (diversification fails)
- Spreads widen 10-20x
- Liquidity evaporates
- **Question**: Would your strategy survive? What's realistic max drawdown?

**Scenario 2: 2020 COVID Crash**
- 30% drawdown in 30 days
- VIX spikes to 80
- Fed intervention uncertainty
- **Question**: Does your edge persist in tail events or is it regime-specific?

**Scenario 3: 2022 Rate Shock**
- Stocks and bonds fall together (60/40 fails)
- Factor crowding unwinds
- Momentum reverses violently
- **Question**: What's your correlation to macro regimes?

**Template**:
"During 2008-style crisis, this strategy would experience:
- Estimated max drawdown: 35-45% (not 12-18% base case)
- Execution costs increase 10x (spreads widen, impact doubles)
- Mean reversion thesis fails if crisis deepens (contagion to mega-caps)
- Exit plan: [specific trigger] or accept drawdown as path to opportunity"
```

**Time**: 60 min
**Priority**: HIGH (realistic risk assessment)

---

## Updated Implementation Priority

### Phase 0 + Phase 1 (Must Do): ~6 hours
*Same as before*

### Phase 3 (Professional Standards): 5-7 hours ‚≠ê RECOMMENDED

**Tier 1 - Critical (4 hours)**:
1. **Benchmark Comparison** (90 min) - Unanimous #1 gap across agents
2. **Execution Cost Estimation** (75 min) - Prevents paper vs real returns gap
3. **Devil's Advocate Stage** (90 min) - Adds missing self-skepticism
4. **Time-Scale Validation** (60 min) - Prevents fantasy edge claims

**Tier 2 - High Priority (3 hours)**:
5. **Capacity Disclosure** (45 min) - Important for scaling
6. **Stress Testing** (60 min) - Realistic risk assessment

**Rationale**: These are professional standards that **all 4 independent reviewers flagged as critical gaps**. Without these, strategies sound sophisticated but fail professional scrutiny.

---

## Updated Success Metrics

### After Phase 0 + Phase 1 + Phase 3

- ‚úÖ Benchmark comparison: 100% of strategies (vs 0% currently)
- ‚úÖ Execution cost awareness: 100% (vs 0% currently)
- ‚úÖ Adversarial review completed: 100% (vs 0% currently)
- ‚úÖ Edge timescale validated: Reduce overstated claims by 80%+
- ‚úÖ Stress testing: 100% include crisis scenarios
- ‚úÖ Deployability score by professional investors: 6-8/10 (vs 2-5/10 currently)

**Target**: Strategies that survive professional investment committee scrutiny, not just pass validation

---

## Multi-Agent Consensus Findings

**Key insight**: 4 independent expert agents (Investor, Risk Manager, Academic, Execution Trader) reviewed same strategies and **converged on identical critical gaps**:

1. ‚úÖ **Benchmark ignorance** (all 4 agents, unanimous)
2. ‚úÖ **Execution costs ignored** (all 4 agents)
3. ‚úÖ **No self-skepticism** (all 4 agents)
4. ‚úÖ **Unrealistic edge timescales** (3 of 4 agents)
5. ‚úÖ **Missing stress testing** (2 of 4 agents)

**Validator**: These aren't my opinions - these are independent professional standards converging.

**Implication**: Phase 3 additions aren't "nice to have" - they're **required to meet professional bar**.

---

## Next Steps

1. **Review Phase 3 additions** - Confirm multi-agent consensus findings
2. **Prioritize implementation** - Phase 0 ‚Üí Phase 1 ‚Üí Phase 3 Tier 1
3. **Implement critical path** (Total: ~10 hours)
   - Phase 0 (35 min): Clear blockers
   - Phase 1 Tier 1 (3 hours): Core quality fixes
   - Phase 3 Tier 1 (4 hours): Professional standards
4. **Validate with test run** - Generate 5 candidates, measure quality improvement
5. **If deployability reaches 6-8/10** ‚Üí Production ready
6. **If still gaps** ‚Üí Implement Phase 1 Tier 2 + Phase 3 Tier 2 (additional 6 hours)

---

## References

- **Architecture Plan**: `docs/prompt_engineering_architecture_plan.md`
- **Analysis Document**: `docs/prompt_engineering_analysis_nov2024.md`
- **Brainstorming Session**: 2025-11-05 (4 parallel expert perspectives)
- **Multi-Agent Analysis**: 2025-11-08 (Investor, Risk Manager, Academic, Execution Trader)
- **Current Issue**: Phase 5 integration test failure (charter truncation + quality gaps)
- **Current Issue**: Task DoXyWF0EnVtwcROhJZ9UR (1 candidate instead of 5, low quality)
